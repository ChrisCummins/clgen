// The file defines the protos for specificying CLgen models.

syntax = "proto2";
package clgen;

import "deeplearning/clgen/proto/corpus.proto";

// The specification of a CLgen model.
message Model {
  optional clgen.Corpus corpus = 1;
  optional NetworkArchitecture architecture = 2;
  optional TrainingOptions training = 3;
}

// The specification of a CLgen language model.
message NetworkArchitecture {
  enum NeuronType {
    UNKNOWN = 0; // The default value is an error.
    LSTM = 1;
    RNN = 2;
    GRU = 3;
  }

  // The type of neuron. Valid options are: {"lstm","rnn","gru"}.
  optional NeuronType neuron_type = 1;
  // The number of neurons in each layer of the network.
  optional int32 neurons_per_layer = 2;
  // The total number of layers in the network.
  optional int32 num_layers = 3;
}

// Options used for training a CLgen language model.
message TrainingOptions {
  // The number of epochs to train the network for.
  optional int32 num_epochs = 1;
  // If true, shuffle the order of contentfiles in the corpus between each
  // training epoch.
  optional bool shuffle_corpus_contentfiles_between_epochs = 2;
  // The training batch size. Note that this is only a *requested* batch size,
  // there may be cases where the runtime decides to modify this value. For
  // example, when the corpus size is smaller than the batch size. Any changes
  // to this value at runtime will be logged as errors.
  optional int32 batch_size = 3;
  // The optimizer configuration.
  oneof optimizer {
    AdamOptimizer adam_optimizer = 10;
  };
}

// The field name suffix '_micros' shows that the value contained in the field
// is converted at runtime to a floating point number by dividing it by 1e6.
// The reason for _micros fields is so that we can realiably encode and compare
// protos without having to worry about floating point rounding and comparisons.

message AdamOptimizer {
  // The initial learning rate. Must be >= 0. A recommended starting value is
  // 2000 (i.e. real value 0.002).
  optional int32 initial_learning_rate_micros = 1;
  // The ratio by which the learning rate decays per epoch of training. Must be
  // >= 0. A recommended starting value is 5000 (i.e. real value 0.05).
  optional int32 learning_rate_decay_per_epoch_micros = 2;
  // Must be in real value range 0 < beta_1 < 1. A recommended starting value
  // is 900000 (i.e. real value 0.9).
  optional int32 beta_1_micros = 3;
  // Must be in real value range 0 < beta_2 < 1. A recommended starting value
  // is 999000 (i.e. real value 0.999).
  optional int32 beta_2_micros = 4;
  // The normalized gradient clip value. A recommended starting value is 5000000
  // (ie. real value 5.0).
  optional int32 normalized_gradient_clip_micros = 5;
}

// A generated sample. Instances of this proto are returned by a Model's
// Sample() method.
message Sample {
  optional string text = 1;
  optional int32 sample_time_ms = 2;
  optional int64 sample_start_epoch_ms_utc = 3;
  optional int32 num_tokens = 4;
}
